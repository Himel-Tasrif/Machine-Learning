{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fc9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f3d6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0f7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a855f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5601ac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7a5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c40e298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758644b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(df.data, columns = df.feature_names)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a97d88dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52d6f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     Target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Target'] = df.target\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e2dbc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     Target Target Name  \n",
       "0         0      setosa  \n",
       "1         0      setosa  \n",
       "2         0      setosa  \n",
       "3         0      setosa  \n",
       "4         0      setosa  \n",
       "..      ...         ...  \n",
       "145       2   virginica  \n",
       "146       2   virginica  \n",
       "147       2   virginica  \n",
       "148       2   virginica  \n",
       "149       2   virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Target Name'] = df1.Target.apply(lambda x: df.target_names[x])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498b0d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.4, 4.8, 4.3, 5.8, 5.7, 5.2, 5.5,\n",
       "       4.5, 5.3, 7. , 6.4, 6.9, 6.5, 6.3, 6.6, 5.9, 6. , 6.1, 5.6, 6.7,\n",
       "       6.2, 6.8, 7.1, 7.6, 7.3, 7.2, 7.7, 7.4, 7.9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['sepal length (cm)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c40d5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "Target               0\n",
       "Target Name          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a6cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    float64\n",
       "sepal width (cm)     float64\n",
       "petal length (cm)    float64\n",
       "petal width (cm)     float64\n",
       "Target                 int32\n",
       "Target Name           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d10869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "80                5.5               2.4                3.8               1.1   \n",
       "79                5.7               2.6                3.5               1.0   \n",
       "\n",
       "    Target Target Name  \n",
       "80       1  versicolor  \n",
       "79       1  versicolor  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da240da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1.drop(['Target','Target Name'], axis = 'columns')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bf4fdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Target, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1.Target\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66921082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06c6a1",
   "metadata": {},
   "source": [
    "## Check Cross Val score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21743c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.93333333, 0.93333333, 0.93333333])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=5, test_size = 0.1)\n",
    "cross_val_score(LogisticRegression(), x, y, cv = ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5db5da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd1e29fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fd6dd",
   "metadata": {},
   "source": [
    "## Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2f5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bffa8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "135 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1.\n",
      " nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1.\n",
      " nan nan nan  1.  1.  1. nan nan nan  1.  1.  1. nan nan nan  1.  1.  1.]\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'poisson', 'absolute_error', 'squared_error', 'friedman_mse'}. Got 'mse' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.84033015 0.84033015]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>LogisticRegression(random_state=10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.395859</td>\n",
       "      <td>Lasso()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support_Vec</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>SVC(C=2.0, gamma='auto', random_state=10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.840330</td>\n",
       "      <td>DecisionTreeRegressor(criterion='friedman_mse')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  best_score  \\\n",
       "0     LogisticRegression    1.000000   \n",
       "1                  Lasso    0.395859   \n",
       "2            Support_Vec    0.946667   \n",
       "3  DecisionTreeRegressor    0.840330   \n",
       "\n",
       "                                          best_est  \n",
       "0              LogisticRegression(random_state=10)  \n",
       "1                                          Lasso()  \n",
       "2        SVC(C=2.0, gamma='auto', random_state=10)  \n",
       "3  DecisionTreeRegressor(criterion='friedman_mse')  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_model_with_param(x,y):\n",
    "    algo = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(),\n",
    "            'params': {\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': [1.0, 2.0, 3.0],\n",
    "                'max_iter': [100, 200, 300],\n",
    "                'random_state': [10,20,42]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'Lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1.0, 2.0, 3.0],\n",
    "                'max_iter': [1000, 2000, 3000]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'Support_Vec': {\n",
    "            'model': SVC(),\n",
    "            'params': {\n",
    "                'C': [1.0, 2.0, 3.0],\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'random_state': [10,20,42]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'DecisionTreeRegressor': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }   \n",
    "    }\n",
    "        \n",
    "    score = []\n",
    "    ss = ShuffleSplit(n_splits = 5, test_size = 0.1)\n",
    "    for algo_name, config in algo.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv = ss, return_train_score = False)\n",
    "        gs.fit(x,y)\n",
    "        score.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_est': gs.best_estimator_\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(score, columns = ['model', 'best_score', 'best_est'])\n",
    "\n",
    "result = best_model_with_param(x,y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "643b5d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = result.loc[result['best_score'].idxmax()]['best_est']\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fef17a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2280870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8817f7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54ffb0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a015178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73     1\n",
       "18     0\n",
       "118    2\n",
       "78     1\n",
       "76     1\n",
       "Name: Target, dtype: int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8457fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a6e8591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e18a730",
   "metadata": {},
   "source": [
    "## Score and Confusion Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4197f607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "971985c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot = True , fmt = 'd', cmap = 'Blues')\n",
    "plt.xlabel('Predicted (y_pred)', color = 'black')\n",
    "plt.ylabel('Actual (y_test)', color = 'black')\n",
    "plt.title(\"Confusion Metrics\", pad = 10, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffd3bf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "73                 6.1               2.8                4.7               1.2\n",
       "18                 5.7               3.8                1.7               0.3\n",
       "118                7.7               2.6                6.9               2.3\n",
       "78                 6.0               2.9                4.5               1.5\n",
       "76                 6.8               2.8                4.8               1.4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a17e0c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73     1\n",
       "18     0\n",
       "118    2\n",
       "78     1\n",
       "76     1\n",
       "Name: Target, dtype: int32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'setosa'  = 0\n",
    "'versicolor' = 1\n",
    "'virginica' = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f1817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f90ba04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75a0b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = sv.fit(x_train, y_train)\n",
    "model1.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d32c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae789a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
