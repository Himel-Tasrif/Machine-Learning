# Feature Engineering
<figure style="text-align: center;">
  <img src="https://serokell.io/files/cf/cfkdnv2r.Feature__Engineering_pic1.png" alt="Machine Learning" width="500" height="250">
</figure>


   1. Improve model accuracy: By providing clearer and more relevant features, the model can learn patterns and relationships more 
      effectively, leading to better predictions.
      
   2. Reduce model complexity: Feature engineering can simplify the data, making it easier for simpler models to perform well, reducing         training time and resource needs.

   3. Handle data issues: It helps address issues like missing values, outliers, and categorical data, ensuring smoother model training.


Types of Feature Engineering:

  a. Feature Selection: Choosing the most informative and relevant features from your data. This can involve statistical tests,                correlation analysis, or domain knowledge.
    
  b. Data Cleaning and Preprocessing: Handling missing values, outliers, inconsistencies, and scaling numerical features to a common     
     range.
     
  c. Feature Creation: Generating new features that capture relationships between existing features or represent complex information in a      more digestible way. 
  
 Examples include:
 
  i. Feature interactions
 ii. Binning
iii. Dimensionality reduction
 iv. Feature Encoding
  v. One-hot encoding
 vi. Label encoding
vii. Frequency encoding
